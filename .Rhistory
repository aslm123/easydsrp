colnames(Performance) <- "Result"
Performance %>% %>% kable(caption="Performance of Decision Tree",digits = 2, format = markdown)
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'markdown')
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html')
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance==1)]
which.max(dtree_threshold$data$performance==1)
dtree_threshold$data$performance==1
dtree_threshold$data$threshold[(dtree_threshold$data$performance==1)]
dtree_threshold$data$threshold[(dtree_threshold$data$performance==1),]
dtree_threshold$data[(dtree_threshold$data$performance==1)]
dtree_threshold$data[(dtree_threshold$data$performance==1),]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"&&dtree_threshold$data$measure=="True Negative rate"])]
which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"&&dtree_threshold$data$measure=="True Negative rate"])
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
==
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]==
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
DecistionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecistionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
DecisionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"), col.names = c('Result'))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = TRUE)
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = RESULT)
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = FALSE, col.names = 'RESULT')
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree (After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree/n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
generateFilterValuesData(dt_task, method = c("information.gain","chi.squared")) %>%
plotFilterValues()
train <- select(Diabetes1, -c(DiabetesPedigreeFunction))
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
train <- select(train, -c(DiabetesPedigreeFunction))
test <- select(test, -c(DiabetesPedigreeFunction))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_task <- makeClassifTask(data=train, target="Outcome"))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_prob <- makeLearner("classif.rpart", predict.type = "prob"))
getParamSet("classif.rpart")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=seq(10,20,1)),
makeDiscreteParam("minbucket", values=seq(round(10/3,0),round(20/3),1)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=seq(4,10,1)),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=seq(5,30,1)))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.01, upper = 0.05),
makeDiscreteParam("maxcompete", values=6),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=10))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
(dtree_predict <- predict(dtree_train, newdata = test))
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = "Result")
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]==
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
DecisionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
)
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.90)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.80)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<1)]
DecisionTree <- dtree_predict %>%
setThreshold(0.01)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>=0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]=0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.6)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.6)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]=0.8)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.8)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.8)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.80)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.80)]
DecisionTree <- dtree_predict %>%
setThreshold(0.1515152)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
DecisionTree <- dtree_predict %>%
setThreshold(0.1616162)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.1)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.12)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.14)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.16)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(c(0.16,0.10))
DecisionTree <- dtree_predict %>%
setThreshold(0.16)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.159)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.1515152)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
)
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 15%)",digits = 2, format = 'html', col.names = 'RESULT')
library(readr)
library(stringr)
source_rmd <- function(file_path) {
stopifnot(is.character(file_path) && length(file_path) == 1)
.tmpfile <- tempfile(fileext = ".R")
.con <- file(.tmpfile)
on.exit(close(.con))
full_rmd <- read_file(file_path)
codes <- str_match_all(string = full_rmd, pattern = "```(?s)\\{r[^{}]*\\}\\s*\\n(.*?)```")
stopifnot(length(codes) == 1 && ncol(codes[[1]]) == 2)
codes <- paste(codes[[1]][, 2], collapse = "\n")
writeLines(codes, .con)
flush(.con)
cat(sprintf("R code extracted to tempfile: %s\nSourcing tempfile...", .tmpfile))
source(.tmpfile)
}
source_rmd("C:/Users/aselr/Documents/GitHub/easydsrp/_posts/2018-11-06-diabetes-among-the-pima-indians-an-exploratory-analysis/diabetes-among-the-pima-indians-an-exploratory-analysis.Rmd")
library(mlr)
library(FSelector)
str(Diabetes1)
Diabetes1 <- as.data.frame(Diabetes1)
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train)
glimpse(Diabetes1)
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train)
test_index <- setdiff(1:nrow(Diabetes1), train_index)
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train_index)
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
list(
train = summary(train),
test = summary(test)
)
colnames(train)[8] <- "Glucose"
colnames(test)[8] <- "Glucose"
(dt_task <- makeClassifTask(data=train, target="Outcome"))
generateFilterValuesData(dt_task, method = c("information.gain","chi.squared")) %>%
plotFilterValues()
train <- select(train, -c(DiabetesPedigreeFunction))
test <- select(test, -c(DiabetesPedigreeFunction))
(dt_task <- makeClassifTask(data=train, target="Outcome"))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_prob <- makeLearner("classif.rpart", predict.type = "prob"))
getParamSet("classif.rpart")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.01, upper = 0.05),
makeDiscreteParam("maxcompete", values=6),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=10))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
(dtree_predict <- predict(dtree_train, newdata = test))
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = "Result")
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
)
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 15%)",digits = 2, format = 'html', col.names = 'RESULT')
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(knitr)
library(pipeR)
Diabetes <- read_csv("C:/Users/aselr/Documents/RMIT/SEMESTER 2 2018/Analysis of Categorical Data/Final Project/Phase 1/diabetes.csv") %>%
as.data.frame()
glimpse(Diabetes)
mlr::summarizeColumns(Diabetes) %>%
kable(caption="Summary Table of Diabetes")
Diabetes$Outcome <- as.factor(unlist(Diabetes$Outcome))
Diabetes$Outcome <- factor(Diabetes$Outcome, levels=c("1", "0"),
labels = c("Positive", "Negative"))
summary(Diabetes$Outcome)
Diabetes$Glucose <-  as.numeric(Diabetes$Glucose)
Diabetes$BloodPressure <-  as.numeric(Diabetes$BloodPressure)
Diabetes$SkinThickness <-  as.numeric(Diabetes$SkinThickness)
Diabetes$Insulin <-  as.numeric(Diabetes$Insulin)
Diabetes$BMI <-  as.numeric(Diabetes$BMI)
Diabetes$Age <- as.integer(Diabetes$Age)
list(
`Column` = colSums(Diabetes==0),
Row = sum(rowSums(Diabetes==0))
)
Diabetes$Pregnancies <- ifelse(Diabetes$Pregnancies==0, "No", "Yes") %>%
factor()
colSums(Diabetes==0)
summary(Diabetes$Pregnancies)
Diabetes$Insulin <- NULL
colSums(Diabetes==0)
Diabetes$SkinThickness <- NULL
colSums(Diabetes==0)
Diabetes$BMI <-
ifelse(Diabetes$BMI<19,"Underweight",
ifelse(Diabetes$BMI>=19 &
Diabetes$BMI<=25, "Normal",
ifelse(Diabetes$BMI>=25 &
Diabetes$BMI<=30, "Overweight","Obese"))) %>%
factor(levels=c("Underweight","Normal",
"Overweight","Obese"))
list(BMI = summary(Diabetes$BMI))
Diabetes$Glucose <- Diabetes$Glucose*0.0555
Diabetes$Glucose <-
if_else(Diabetes$Glucose<2.2,"Hypoglycemia",
if_else(Diabetes$Glucose>=2.2 &
Diabetes$Glucose<=7.8,"Normal",
if_else(Diabetes$Glucose>7.8 &
Diabetes$Glucose<=11.1,
"Hyperglycemia","Diabetes"))) %>%
factor()
list(
`Test Result` = summary(Diabetes$Glucose)
)
Diabetes$BloodPressure <- NULL
load('C:/Users/aselr/Documents/R Programming/mode.rda') # Function to calculate mode
str(mode)
ggplot(Diabetes, aes(y=Age, x=Outcome)) +
geom_boxplot() + geom_jitter()+
theme_bw() +
xlab("Outcome") + ylab("Age") +
stat_summary(fun.y=mode, colour="Orange",
geom="point", shape=16, size=5) +
stat_summary(fun.y=mean, colour="purple",
geom="point", shape=16, size=5) +
ggtitle(label="Age by Outcome",
subtitle = "Orange=Most Frequent\nPurple=Average Age") +
theme(axis.text.x = element_text(face="bold",size=12),
axis.text.y = element_text(face="bold",size=12),
title = element_text(face="bold",size=12),
axis.title = element_text(face="bold",size=12)) +
scale_y_continuous(breaks=seq(20,80,4))
ggplot(Diabetes, aes(y=DiabetesPedigreeFunction, x=Outcome)) +
geom_boxplot() + geom_jitter()+
theme_bw() +
xlab("Outcome") + ylab("DiabetesPedigreeFunction") +
stat_summary(fun.y=mode, colour="orange",
geom="point", shape=16, size=5) +
stat_summary(fun.y=mean, colour="purple",
geom="point", shape=16, size=5) +
ggtitle(label="Diabetes Pedigree Function by Outcome",
subtitle = "Orange=Most Frequent\nPurple=Average Age") +
theme(axis.text.x = element_text(face="bold",size=12),
axis.text.y = element_text(face="bold",size=12),
title = element_text(face="bold",size=12),
axis.title = element_text(face="bold",size=12)) +
scale_y_continuous(breaks=seq(0,3,0.5))
(pregnant <- table(Diabetes$Pregnancies, Diabetes$Outcome,
dnn = c("Pregnant", "Outcome")) )
pregnant %>% prop.table(2) %>% round(2) %>%
kable(format = 'html')
(bmi <- table(Diabetes$BMI, Diabetes$Outcome,
dnn = c("BMI", "Outcome"))  )
bmi %>% prop.table(2)%>% round(2) %>%
kable(format = 'html')
(glucose <- table(Diabetes$Glucose, Diabetes$Outcome,
dnn = c("Glucose Level", "Outcome")) )
glucose %>% prop.table(2) %>% round(2) %>%
kable(format = 'html')
summary(Diabetes)
library(readr)
library(stringr)
source_rmd <- function(file_path) {
stopifnot(is.character(file_path) && length(file_path) == 1)
.tmpfile <- tempfile(fileext = ".R")
.con <- file(.tmpfile)
on.exit(close(.con))
full_rmd <- read_file(file_path)
codes <- str_match_all(string = full_rmd, pattern = "```(?s)\\{r[^{}]*\\}\\s*\\n(.*?)```")
stopifnot(length(codes) == 1 && ncol(codes[[1]]) == 2)
codes <- paste(codes[[1]][, 2], collapse = "\n")
writeLines(codes, .con)
flush(.con)
cat(sprintf("R code extracted to tempfile: %s\nSourcing tempfile...", .tmpfile))
source(.tmpfile)
}
source_rmd("C:/Users/aselr/Documents/GitHub/easydsrp/_posts/2018-11-06-diabetes-among-the-pima-indians-an-exploratory-analysis/diabetes-among-the-pima-indians-an-exploratory-analysis.Rmd")
library(mlr)
library(FSelector)
library(rpart.plot)
glimpse(Diabetes)
train_index <- sample(1:nrow(Diabetes), 0.8 * nrow(Diabetes))
test_index <- setdiff(1:nrow(Diabetes), train_index)
train <- Diabetes[train_index,]
test <- Diabetes[test_index,]
list(
train = summary(train),
test = summary(test)
)
(dt_task <- makeClassifTask(data=train, target="Outcome"))
(dt_prob <- makeLearner('classif.rpart', predict.type="prob"))
listFilterMethods()
generateFilterValuesData(dt_task, method = c("information.gain","chi.squared",  "gain.ratio")) %>%
plotFilterValues()
generateFeatureImportanceData(task=dt_task, learner = dt_prob,measure = tpr, interaction = FALSE)
generateFeatureImportanceData(task=dt_task, learner = dt_prob,measure = auc, interaction = FALSE)
train <- select(train, -Pregnancies)
test <- select(test, -Pregnancies)
list(
train = summary(train),
test = summary(test)
)
train <- filter(train, Glucose!='Hypoglycemia') %>% droplevels()
test <- filter(test, Glucose!='Hypoglycemia') %>% droplevels()
list(
train = summary(train),
test = summary(test)
)
(dt_task <- makeClassifTask(data=train, target="Outcome"))
getParamSet("classif.rpart")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=seq(5,10,1)),
makeDiscreteParam("minbucket", values=seq(round(5/3,0), round(10/3,0), 1)),
makeNumericParam("cp", lower = 0.01, upper = 0.05),
makeDiscreteParam("maxcompete", values=6),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=10)
)
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L, stratify=TRUE)
(dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc, fnr, mmce, tnr, setAggregation(tpr, test.sd)),
par.set=dt_param,
control=ctrl,
task=dt_task,
show.info = TRUE)
)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optimal Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
rpart.plot(dtree_train$learner.model, roundint=FALSE, varlen=3, type = 3, clip.right.labs = FALSE, yesno = 2)
rpart.rules(dtree_train$learner.model, roundint = FALSE)
(dtree_predict <- predict(dtree_train, newdata = test))
dtree_predict %>%
calculateROCMeasures()
Performance <- performance(dtree_predict, measures = list(tpr,auc,mmce, acc,tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "Mean Misclassification Error","Accuracy","True Negative Rate"))
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = "Result")
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc, mmce,tnr)) %>%
plotThreshVsPerf() +
geom_point()
)
list(
`TPR Threshold for 100%`  = tpr_threshold100 <-
dtree_threshold$data$threshold[
which.max(dtree_threshold$data$performance[
dtree_threshold$data$measure=="True positive rate"]<1)],
`TPR Threshold for 80%` = tpr_threshold80 <-
dtree_threshold$data$threshold[
which.min(dtree_threshold$data$performance[
dtree_threshold$data$measure=="True positive rate"]>0.80)],
`Average Threshold` = avg_threshold <- mean(c(tpr_threshold100,tpr_threshold80)),
`TNR Threshold for 80%` = tnr_threshold80 <-
dtree_threshold$data$threshold[
which.max(dtree_threshold$data$performance[
dtree_threshold$data$measure=="True negative rate"]>0.70)]
)
DecisionTree <- dtree_predict %>%
setThreshold(avg_threshold)
(dt_performance <-
DecisionTree %>%
performance(measures = list(tpr,auc, mmce,tnr))
)
(dt_cm <-
DecisionTree %>%
calculateROCMeasures()
)
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc, mmce, acc, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "Mean Misclassification Error","Accuracy","True Negative Rate"))
Performance_threshold %>%  kable(caption=paste("Performance of Decision Tree\n\nAfter Thresholding to",(avg_threshold*100) %>% round(0),'%'),digits = 2, format = 'html', col.names = 'RESULT')
