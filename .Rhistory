control=ctrl,
task=dt_task)
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=Inf),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=5))
dt_tuneparam <- tuneParams(learner=dt_response,
resampling=rdesc,
measures=list(tpr,auc,f1, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=10),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=5))
dt_tuneparam <- tuneParams(learner=dt_response,
resampling=rdesc,
measures=list(tpr,auc,f1, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
generateHyperParsEffectData(dt_tuneparam)
generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=c(10,20),
makeDiscreteParam("minbucket", values=c(round(10/3,0),round(20/3)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=c(4,10),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=c(5,30))
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=c(10,20)),
makeDiscreteParam("minbucket", values=c(round(10/3,0),round(20/3))),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=c(4,10)),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=c(5,30)))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
(dt_hyperparam <- generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE))
plotHyperParsEffect(dt_hyperparam)
plotHyperParsEffect(dt_hyperparam, x=minsplit)
plotHyperParsEffect(dt_hyperparam, x="minsplit")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn=dt_prob)
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="dt_prob")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="classif.rpart")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="rpart")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr,bst")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst")
install.packages("bst")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst")
install.packages("mmpf")
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=seq(10,20,1)),
makeDiscreteParam("minbucket", values=seq(round(10/3,0),round(20/3),1)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=seq(4,10,1)),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=seq(5,30,1)))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst")
#install bst, mmpf
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_x_continuous(breaks = c(0.5,0.75))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = c(0.5,0.75))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = c(0.500,0.750))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = seq(0.500,0.750,0.1))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = seq(0.500,0.750))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = seq(0.500,0.750,0.01))
plotHyperParsEffect(dt_hyperparam, x="minsplit", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = seq(0.100,0.750,0.01))
plotHyperParsEffect(dt_hyperparam, x="maxdepth", y="tpr.test.mean", partial.dep.learn="regr.bst") +
scale_y_continuous(breaks = seq(0.100,0.750,0.01))
dt_hyperparam$measures
dt_tuneparam $x
dt_tuneparam$x
dt_tuneparam$y
dt_tuneparam$threshold
dt_tuneparam$control
dt_tuneparam$opt.path
list(
`Optimal HyperParameters` = dt_tuneparam$x
`Optima Metrics` = dt_tuneparam$y
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
(dtree_predict <- predict(dtree_train, newdata = test))
performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
(dtree+threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=='True'])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=='True positive rate'])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=='True positive rate',])]
dtree_threshold$data
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance)]
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])
which.max(dtree_threshold$data$performance==0.75)
dtree_threshold$data
dtree_threshold$data[dtree_threshold$data$measure=='True positive rate']
dtree_threshold$data[dtree_threshold$data$measure=='True positive rate',]
dtree_predict %>%
setThreshold(0.19191919)
dtree_predict %>%
setThreshold(0.19191919) %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
dtree_predict %>%
setThreshold(0.19191919) %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
calculateROCMeasures()
dtree_predict %>%
setThreshold(0.19191919) %>%
calculateROCMeasures()
dtree_predict %>%
setThreshold(0.19191919) %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
dtree_predict %>%
setThreshold(0.19191919) %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
predict(dtreetrain, dt_task)
predict(dtree_train, dt_task)
calculateROCMeasurespredict((dtree_train, dt_task))
calculateROCMeasurespredict(predict(dtree_train, dt_task))
calculateROCMeasures(predict(dtree_train, dt_task))
generateThreshVsPerfData(predict(dtree_train, dt_task), measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
kable(caption="Performance of Decistion Tree")
performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame()
performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(col.names=c("Result"))
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame()
colnames(Performance) <- "Result"
Performance
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% round(2)
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% round(2) %>% scales::percent()
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% scales::percent()
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
unlist(Performance) %>% scales::percent()
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% round(2)
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% round(2) %>% kable(caption="Performance of Decision Tree")
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>% %>% kable(caption="Performance of Decision Tree",digits = 2, format = markdown)
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
colnames(Performance) <- "Result"
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'markdown')
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html')
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[which.max(dtree_threshold$data$performance==1)]
which.max(dtree_threshold$data$performance==1)
dtree_threshold$data$performance==1
dtree_threshold$data$threshold[(dtree_threshold$data$performance==1)]
dtree_threshold$data$threshold[(dtree_threshold$data$performance==1),]
dtree_threshold$data[(dtree_threshold$data$performance==1)]
dtree_threshold$data[(dtree_threshold$data$performance==1),]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"&&dtree_threshold$data$measure=="True Negative rate"])]
which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"&&dtree_threshold$data$measure=="True Negative rate"])
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True Negative rate"])]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
==
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]==
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
DecistionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecistionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
DecisionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"), col.names = c('Result'))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = TRUE)
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = RESULT)
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = TRUE, col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', row.names = FALSE, col.names = 'RESULT')
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree (After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree/n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
generateFilterValuesData(dt_task, method = c("information.gain","chi.squared")) %>%
plotFilterValues()
train <- select(Diabetes1, -c(DiabetesPedigreeFunction))
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
train <- select(train, -c(DiabetesPedigreeFunction))
test <- select(test, -c(DiabetesPedigreeFunction))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_task <- makeClassifTask(data=train, target="Outcome"))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_prob <- makeLearner("classif.rpart", predict.type = "prob"))
getParamSet("classif.rpart")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=seq(10,20,1)),
makeDiscreteParam("minbucket", values=seq(round(10/3,0),round(20/3),1)),
makeNumericParam("cp", lower = 0.02, upper = 0.05),
makeDiscreteParam("maxcompete", values=seq(4,10,1)),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=seq(5,30,1)))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.01, upper = 0.05),
makeDiscreteParam("maxcompete", values=6),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=10))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
(dtree_predict <- predict(dtree_train, newdata = test))
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = "Result")
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])]==
dtree_threshold$data$threshold[ which.min(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
DecisionTree <- dtree_predict %>%
setThreshold(0.19191919)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"])],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"])]
)
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.90)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.80)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<1)]
DecisionTree <- dtree_predict %>%
setThreshold(0.01)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>=0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]=0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.7)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.6)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.6)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]=0.8)]
dtree_threshold$data$threshold[ which(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]==0.8)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]>0.8)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.80)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<0.80)]
DecisionTree <- dtree_predict %>%
setThreshold(0.1515152)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)]
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
DecisionTree <- dtree_predict %>%
setThreshold(0.1616162)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.1)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.12)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.14)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.16)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(c(0.16,0.10))
DecisionTree <- dtree_predict %>%
setThreshold(0.16)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.159)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.1515152)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
)
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 19%)",digits = 2, format = 'html', col.names = 'RESULT')
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 15%)",digits = 2, format = 'html', col.names = 'RESULT')
library(readr)
library(stringr)
source_rmd <- function(file_path) {
stopifnot(is.character(file_path) && length(file_path) == 1)
.tmpfile <- tempfile(fileext = ".R")
.con <- file(.tmpfile)
on.exit(close(.con))
full_rmd <- read_file(file_path)
codes <- str_match_all(string = full_rmd, pattern = "```(?s)\\{r[^{}]*\\}\\s*\\n(.*?)```")
stopifnot(length(codes) == 1 && ncol(codes[[1]]) == 2)
codes <- paste(codes[[1]][, 2], collapse = "\n")
writeLines(codes, .con)
flush(.con)
cat(sprintf("R code extracted to tempfile: %s\nSourcing tempfile...", .tmpfile))
source(.tmpfile)
}
source_rmd("C:/Users/aselr/Documents/GitHub/easydsrp/_posts/2018-11-06-diabetes-among-the-pima-indians-an-exploratory-analysis/diabetes-among-the-pima-indians-an-exploratory-analysis.Rmd")
library(mlr)
library(FSelector)
str(Diabetes1)
Diabetes1 <- as.data.frame(Diabetes1)
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train)
glimpse(Diabetes1)
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train)
test_index <- setdiff(1:nrow(Diabetes1), train_index)
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
train_index <- sample(1:nrow(Diabetes1), 0.8 * nrow(Diabetes1))
test_index <- setdiff(1:nrow(Diabetes1), train_index)
train <- Diabetes1[train_index,]
test <- Diabetes1[test_index,]
list(
train = summary(train),
test = summary(test)
)
colnames(train)[8] <- "Glucose"
colnames(test)[8] <- "Glucose"
(dt_task <- makeClassifTask(data=train, target="Outcome"))
generateFilterValuesData(dt_task, method = c("information.gain","chi.squared")) %>%
plotFilterValues()
train <- select(train, -c(DiabetesPedigreeFunction))
test <- select(test, -c(DiabetesPedigreeFunction))
(dt_task <- makeClassifTask(data=train, target="Outcome"))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 2L, stratify=TRUE)
(dt_prob <- makeLearner("classif.rpart", predict.type = "prob"))
getParamSet("classif.rpart")
dt_param <- makeParamSet(
makeDiscreteParam("minsplit", values=10),
makeDiscreteParam("minbucket", values=round(10/3,0)),
makeNumericParam("cp", lower = 0.01, upper = 0.05),
makeDiscreteParam("maxcompete", values=6),
makeDiscreteParam("usesurrogate", values=0),
makeDiscreteParam("maxdepth", values=10))
dt_tuneparam <- tuneParams(learner=dt_prob,
resampling=rdesc,
measures=list(tpr,auc,f1, acc, mmce, timepredict, tnr),
par.set=dt_param,
control=ctrl,
task=dt_task)
list(
`Optimal HyperParameters` = dt_tuneparam$x,
`Optima Metrics` = dt_tuneparam$y
)
dtree <- setHyperPars(dt_prob, par.vals = dt_tuneparam$x)
dtree_train <- train(learner=dtree, task=dt_task)
getLearnerModel(dtree_train)
(dtree_predict <- predict(dtree_train, newdata = test))
Performance <- performance(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance %>%  kable(caption="Performance of Decision Tree",digits = 2, format = 'html', col.names = "Result")
(dtree_threshold <-
generateThreshVsPerfData(dtree_predict, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
plotThreshVsPerf()
)
mean(
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True negative rate"]>0.70)],
dtree_threshold$data$threshold[ which.max(dtree_threshold$data$performance[dtree_threshold$data$measure=="True positive rate"]<=0.80)]
)
DecisionTree <- dtree_predict %>%
setThreshold(0.15)
DecisionTree %>%
performance(measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr))
DecisionTree %>%
calculateROCMeasures()
Performance_threshold <- performance(DecisionTree, measures = list(tpr,auc,f1, mmce, acc, timepredict, tnr)) %>%
as.data.frame(row.names = c("True Positive","Area Under Curve", "F1", "Mean Misclassification Error","Accuracy","Time to Predict","True Negative Rate"))
Performance_threshold %>%  kable(caption="Performance of Decision Tree\n\n(After Thresholding to 15%)",digits = 2, format = 'html', col.names = 'RESULT')
